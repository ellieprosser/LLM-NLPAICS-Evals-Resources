# LLM-NLPAICS-Evals-Resources

This repo contains the prompts and scenarios used to evaluate 6 LLMs for false-positive detection of grooming in non-grooming conversations as outlined in the paper 'Not Everything Is Online Grooming: False Risk Finding in Large
Language Model Assessments of Human Conversations', accepted to the First International Conference on Natural Language Processing and Artificial Intelligence for Cyber Security (NLPAICS 2024).

### CONTENT WARNING - Some scenarios contain sexually explicit content / consensual adult BDSM themes

BibTeX Citation:
```
@inproceedings{prosser2024not,
  title        = {Not Everything Is Online Grooming: False Risk Finding in Large Language Model Assessments of Human Conversations},
  author       = {Ellie Prosser and Matthew Edwards},
  year         = 2024,
  booktitle    = {First International Conference on Natural Language Processing and Artificial Intelligence for Cyber Security (NLPAICS 2024)}}
```
